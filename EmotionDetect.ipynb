{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Emotion-Detection/data/train/'\n",
    "test_dir = '../Emotion-Detection/data/test/'\n",
    "\n",
    "row = 48\n",
    "col = 48\n",
    "classes = len(os.listdir(train_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                   zoom_range = 0.3,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_dir,\n",
    "                                                 batch_size = 64,\n",
    "                                                 target_size = (row, col),\n",
    "                                                 shuffle = True,\n",
    "                                                 color_mode = 'grayscale',\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_set = test_datagen.flow_from_directory(test_dir,\n",
    "                                            batch_size = 64,\n",
    "                                            target_size = (row, col),\n",
    "                                            shuffle = True,\n",
    "                                            color_mode = 'grayscale',\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'happy': 3,\n",
       " 'neutral': 4,\n",
       " 'sad': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating The Model Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_size, classes = 7):\n",
    "  \n",
    "  model = tf.keras.Sequential()\n",
    "  \n",
    "  model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_size, activation = 'relu'))\n",
    "  model.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Dropout(0.25))\n",
    "  \n",
    "  model.add(Conv2D(128, (3, 3), padding='same', activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "  model.add(Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Dropout(0.25))\n",
    "  \n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(1024, activation = 'relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  \n",
    "  model.add(Dense(7, activation = 'softmax'))\n",
    "  \n",
    "  model.compile(optimizer = Adam(lr=0.0001, decay=1e-6), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 17:12:22.560210: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-03 17:12:22.560562: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 22, 22, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 22, 22, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 11, 11, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 11, 11, 256)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30976)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              31720448  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,116,743\n",
      "Trainable params: 32,116,103\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fbrynpk/Desktop/Emotion-Detection/.venv/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = get_model((row, col, 1), classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_path = 'model.h5'\n",
    "log_dir = \"checkpoint/logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(chk_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=3, verbose=1, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=6, verbose=1, min_delta=0.0001)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 2.4804 - accuracy: 0.4252\n",
      "Epoch 1: val_accuracy improved from -inf to 0.46191, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 2.4804 - accuracy: 0.4252 - val_loss: 2.2473 - val_accuracy: 0.4619 - lr: 1.0000e-04\n",
      "Epoch 2/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 2.1910 - accuracy: 0.4417\n",
      "Epoch 2: val_accuracy improved from 0.46191 to 0.48256, saving model to model.h5\n",
      "448/448 [==============================] - 31s 68ms/step - loss: 2.1910 - accuracy: 0.4417 - val_loss: 1.9856 - val_accuracy: 0.4826 - lr: 1.0000e-04\n",
      "Epoch 3/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.9496 - accuracy: 0.4672\n",
      "Epoch 3: val_accuracy improved from 0.48256 to 0.50823, saving model to model.h5\n",
      "448/448 [==============================] - 31s 68ms/step - loss: 1.9496 - accuracy: 0.4672 - val_loss: 1.7617 - val_accuracy: 0.5082 - lr: 1.0000e-04\n",
      "Epoch 4/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.7679 - accuracy: 0.4868\n",
      "Epoch 4: val_accuracy improved from 0.50823 to 0.52455, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.7679 - accuracy: 0.4868 - val_loss: 1.6093 - val_accuracy: 0.5246 - lr: 1.0000e-04\n",
      "Epoch 5/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.6258 - accuracy: 0.5058\n",
      "Epoch 5: val_accuracy improved from 0.52455 to 0.53097, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.6258 - accuracy: 0.5058 - val_loss: 1.5169 - val_accuracy: 0.5310 - lr: 1.0000e-04\n",
      "Epoch 6/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.5220 - accuracy: 0.5198\n",
      "Epoch 6: val_accuracy improved from 0.53097 to 0.54869, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.5220 - accuracy: 0.5198 - val_loss: 1.4199 - val_accuracy: 0.5487 - lr: 1.0000e-04\n",
      "Epoch 7/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.4332 - accuracy: 0.5397\n",
      "Epoch 7: val_accuracy improved from 0.54869 to 0.56822, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.4332 - accuracy: 0.5397 - val_loss: 1.3394 - val_accuracy: 0.5682 - lr: 1.0000e-04\n",
      "Epoch 8/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.3706 - accuracy: 0.5521\n",
      "Epoch 8: val_accuracy improved from 0.56822 to 0.57533, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.3706 - accuracy: 0.5521 - val_loss: 1.2867 - val_accuracy: 0.5753 - lr: 1.0000e-04\n",
      "Epoch 9/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.3081 - accuracy: 0.5632\n",
      "Epoch 9: val_accuracy improved from 0.57533 to 0.58789, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.3081 - accuracy: 0.5632 - val_loss: 1.2473 - val_accuracy: 0.5879 - lr: 1.0000e-04\n",
      "Epoch 10/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.2629 - accuracy: 0.5729\n",
      "Epoch 10: val_accuracy did not improve from 0.58789\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 1.2629 - accuracy: 0.5729 - val_loss: 1.2200 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 11/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.2230 - accuracy: 0.5867\n",
      "Epoch 11: val_accuracy improved from 0.58789 to 0.59054, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.2230 - accuracy: 0.5867 - val_loss: 1.2215 - val_accuracy: 0.5905 - lr: 1.0000e-04\n",
      "Epoch 12/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.1913 - accuracy: 0.5963\n",
      "Epoch 12: val_accuracy improved from 0.59054 to 0.59947, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.1913 - accuracy: 0.5963 - val_loss: 1.1827 - val_accuracy: 0.5995 - lr: 1.0000e-04\n",
      "Epoch 13/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.1514 - accuracy: 0.6089\n",
      "Epoch 13: val_accuracy improved from 0.59947 to 0.60519, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.1514 - accuracy: 0.6089 - val_loss: 1.1653 - val_accuracy: 0.6052 - lr: 1.0000e-04\n",
      "Epoch 14/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.1181 - accuracy: 0.6216\n",
      "Epoch 14: val_accuracy improved from 0.60519 to 0.60547, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.1181 - accuracy: 0.6216 - val_loss: 1.1680 - val_accuracy: 0.6055 - lr: 1.0000e-04\n",
      "Epoch 15/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.0925 - accuracy: 0.6296\n",
      "Epoch 15: val_accuracy improved from 0.60547 to 0.61161, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0925 - accuracy: 0.6296 - val_loss: 1.1451 - val_accuracy: 0.6116 - lr: 1.0000e-04\n",
      "Epoch 16/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.0692 - accuracy: 0.6357\n",
      "Epoch 16: val_accuracy improved from 0.61161 to 0.61816, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0692 - accuracy: 0.6357 - val_loss: 1.1232 - val_accuracy: 0.6182 - lr: 1.0000e-04\n",
      "Epoch 17/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.0449 - accuracy: 0.6492\n",
      "Epoch 17: val_accuracy did not improve from 0.61816\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 1.0449 - accuracy: 0.6492 - val_loss: 1.1222 - val_accuracy: 0.6159 - lr: 1.0000e-04\n",
      "Epoch 18/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.0233 - accuracy: 0.6536\n",
      "Epoch 18: val_accuracy improved from 0.61816 to 0.61998, saving model to model.h5\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 1.0233 - accuracy: 0.6536 - val_loss: 1.1307 - val_accuracy: 0.6200 - lr: 1.0000e-04\n",
      "Epoch 19/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.0013 - accuracy: 0.6626\n",
      "Epoch 19: val_accuracy improved from 0.61998 to 0.62374, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 1.0013 - accuracy: 0.6626 - val_loss: 1.1134 - val_accuracy: 0.6237 - lr: 1.0000e-04\n",
      "Epoch 20/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.9688 - accuracy: 0.6743\n",
      "Epoch 20: val_accuracy improved from 0.62374 to 0.62891, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 0.9688 - accuracy: 0.6743 - val_loss: 1.1077 - val_accuracy: 0.6289 - lr: 1.0000e-04\n",
      "Epoch 21/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.9507 - accuracy: 0.6840\n",
      "Epoch 21: val_accuracy did not improve from 0.62891\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.9507 - accuracy: 0.6840 - val_loss: 1.1417 - val_accuracy: 0.6270 - lr: 1.0000e-04\n",
      "Epoch 22/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.9368 - accuracy: 0.6883\n",
      "Epoch 22: val_accuracy improved from 0.62891 to 0.63951, saving model to model.h5\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.9368 - accuracy: 0.6883 - val_loss: 1.0859 - val_accuracy: 0.6395 - lr: 1.0000e-04\n",
      "Epoch 23/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.9055 - accuracy: 0.6991\n",
      "Epoch 23: val_accuracy did not improve from 0.63951\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 0.9055 - accuracy: 0.6991 - val_loss: 1.1094 - val_accuracy: 0.6378 - lr: 1.0000e-04\n",
      "Epoch 24/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.8861 - accuracy: 0.7058\n",
      "Epoch 24: val_accuracy did not improve from 0.63951\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.8861 - accuracy: 0.7058 - val_loss: 1.1433 - val_accuracy: 0.6274 - lr: 1.0000e-04\n",
      "Epoch 25/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.8708 - accuracy: 0.7128\n",
      "Epoch 25: val_accuracy did not improve from 0.63951\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.8708 - accuracy: 0.7128 - val_loss: 1.0986 - val_accuracy: 0.6357 - lr: 1.0000e-04\n",
      "Epoch 26/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.8523 - accuracy: 0.7210\n",
      "Epoch 26: val_accuracy did not improve from 0.63951\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.8523 - accuracy: 0.7210 - val_loss: 1.0757 - val_accuracy: 0.6362 - lr: 1.0000e-04\n",
      "Epoch 27/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.8331 - accuracy: 0.7294\n",
      "Epoch 27: val_accuracy did not improve from 0.63951\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.8331 - accuracy: 0.7294 - val_loss: 1.1306 - val_accuracy: 0.6267 - lr: 1.0000e-04\n",
      "Epoch 28/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.8117 - accuracy: 0.7350\n",
      "Epoch 28: val_accuracy did not improve from 0.63951\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "448/448 [==============================] - 31s 69ms/step - loss: 0.8117 - accuracy: 0.7350 - val_loss: 1.1284 - val_accuracy: 0.6391 - lr: 1.0000e-04\n",
      "Epoch 29/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.7499 - accuracy: 0.7617\n",
      "Epoch 29: val_accuracy improved from 0.63951 to 0.65193, saving model to model.h5\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.7499 - accuracy: 0.7617 - val_loss: 1.0947 - val_accuracy: 0.6519 - lr: 2.0000e-05\n",
      "Epoch 30/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.7204 - accuracy: 0.7702\n",
      "Epoch 30: val_accuracy did not improve from 0.65193\n",
      "448/448 [==============================] - 31s 68ms/step - loss: 0.7204 - accuracy: 0.7702 - val_loss: 1.0765 - val_accuracy: 0.6519 - lr: 2.0000e-05\n",
      "Epoch 31/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.7055 - accuracy: 0.7735\n",
      "Epoch 31: val_accuracy improved from 0.65193 to 0.65304, saving model to model.h5\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.7055 - accuracy: 0.7735 - val_loss: 1.1055 - val_accuracy: 0.6530 - lr: 2.0000e-05\n",
      "Epoch 32/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.6910 - accuracy: 0.7800\n",
      "Epoch 32: val_accuracy did not improve from 0.65304\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.6910 - accuracy: 0.7800 - val_loss: 1.1000 - val_accuracy: 0.6526 - lr: 2.0000e-05\n",
      "Epoch 33/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.7844\n",
      "Epoch 33: val_accuracy improved from 0.65304 to 0.65472, saving model to model.h5\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.6871 - accuracy: 0.7844 - val_loss: 1.0928 - val_accuracy: 0.6547 - lr: 2.0000e-05\n",
      "Epoch 34/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.6701 - accuracy: 0.7899\n",
      "Epoch 34: val_accuracy improved from 0.65472 to 0.65653, saving model to model.h5\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.6701 - accuracy: 0.7899 - val_loss: 1.0944 - val_accuracy: 0.6565 - lr: 2.0000e-05\n",
      "Epoch 35/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.6625 - accuracy: 0.7878\n",
      "Epoch 35: val_accuracy did not improve from 0.65653\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.6625 - accuracy: 0.7878 - val_loss: 1.1088 - val_accuracy: 0.6554 - lr: 2.0000e-05\n",
      "Epoch 36/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.6548 - accuracy: 0.7938\n",
      "Epoch 36: val_accuracy did not improve from 0.65653\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.6548 - accuracy: 0.7938 - val_loss: 1.1244 - val_accuracy: 0.6530 - lr: 2.0000e-05\n",
      "Epoch 37/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.6433 - accuracy: 0.7966\n",
      "Epoch 37: val_accuracy improved from 0.65653 to 0.65820, saving model to model.h5\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.6433 - accuracy: 0.7966 - val_loss: 1.1018 - val_accuracy: 0.6582 - lr: 2.0000e-05\n",
      "Epoch 38/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.6353 - accuracy: 0.8009\n",
      "Epoch 38: val_accuracy did not improve from 0.65820\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.6353 - accuracy: 0.8009 - val_loss: 1.1180 - val_accuracy: 0.6568 - lr: 2.0000e-05\n",
      "Epoch 39/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.8022\n",
      "Epoch 39: val_accuracy improved from 0.65820 to 0.65890, saving model to model.h5\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.6236 - accuracy: 0.8022 - val_loss: 1.1069 - val_accuracy: 0.6589 - lr: 2.0000e-05\n",
      "Epoch 40/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.6266 - accuracy: 0.8056\n",
      "Epoch 40: val_accuracy did not improve from 0.65890\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.6266 - accuracy: 0.8056 - val_loss: 1.1093 - val_accuracy: 0.6579 - lr: 2.0000e-05\n",
      "Epoch 41/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.6149 - accuracy: 0.8076\n",
      "Epoch 41: val_accuracy did not improve from 0.65890\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.6149 - accuracy: 0.8076 - val_loss: 1.1253 - val_accuracy: 0.6562 - lr: 2.0000e-05\n",
      "Epoch 42/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.6103 - accuracy: 0.8076\n",
      "Epoch 42: val_accuracy improved from 0.65890 to 0.66044, saving model to model.h5\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.6103 - accuracy: 0.8076 - val_loss: 1.1186 - val_accuracy: 0.6604 - lr: 2.0000e-05\n",
      "Epoch 43/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5986 - accuracy: 0.8134\n",
      "Epoch 43: val_accuracy did not improve from 0.66044\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.5986 - accuracy: 0.8134 - val_loss: 1.1103 - val_accuracy: 0.6569 - lr: 2.0000e-05\n",
      "Epoch 44/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5868 - accuracy: 0.8163\n",
      "Epoch 44: val_accuracy did not improve from 0.66044\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.5868 - accuracy: 0.8163 - val_loss: 1.1304 - val_accuracy: 0.6540 - lr: 2.0000e-05\n",
      "Epoch 45/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5815 - accuracy: 0.8183\n",
      "Epoch 45: val_accuracy did not improve from 0.66044\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.5815 - accuracy: 0.8183 - val_loss: 1.1276 - val_accuracy: 0.6567 - lr: 2.0000e-05\n",
      "Epoch 46/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5755 - accuracy: 0.8188\n",
      "Epoch 46: val_accuracy did not improve from 0.66044\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.5755 - accuracy: 0.8188 - val_loss: 1.1307 - val_accuracy: 0.6560 - lr: 2.0000e-05\n",
      "Epoch 47/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5739 - accuracy: 0.8198\n",
      "Epoch 47: val_accuracy did not improve from 0.66044\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.5739 - accuracy: 0.8198 - val_loss: 1.1530 - val_accuracy: 0.6586 - lr: 2.0000e-05\n",
      "Epoch 48/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5670 - accuracy: 0.8236\n",
      "Epoch 48: val_accuracy did not improve from 0.66044\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.5670 - accuracy: 0.8236 - val_loss: 1.1420 - val_accuracy: 0.6602 - lr: 2.0000e-05\n",
      "Epoch 49/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5572 - accuracy: 0.8276\n",
      "Epoch 49: val_accuracy improved from 0.66044 to 0.66099, saving model to model.h5\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.5572 - accuracy: 0.8276 - val_loss: 1.1302 - val_accuracy: 0.6610 - lr: 4.0000e-06\n",
      "Epoch 50/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5565 - accuracy: 0.8280\n",
      "Epoch 50: val_accuracy improved from 0.66099 to 0.66197, saving model to model.h5\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5565 - accuracy: 0.8280 - val_loss: 1.1244 - val_accuracy: 0.6620 - lr: 4.0000e-06\n",
      "Epoch 51/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5464 - accuracy: 0.8315\n",
      "Epoch 51: val_accuracy did not improve from 0.66197\n",
      "448/448 [==============================] - 29s 65ms/step - loss: 0.5464 - accuracy: 0.8315 - val_loss: 1.1317 - val_accuracy: 0.6620 - lr: 4.0000e-06\n",
      "Epoch 52/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5511 - accuracy: 0.8283\n",
      "Epoch 52: val_accuracy did not improve from 0.66197\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5511 - accuracy: 0.8283 - val_loss: 1.1375 - val_accuracy: 0.6614 - lr: 4.0000e-06\n",
      "Epoch 53/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5459 - accuracy: 0.8314\n",
      "Epoch 53: val_accuracy improved from 0.66197 to 0.66392, saving model to model.h5\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 0.5459 - accuracy: 0.8314 - val_loss: 1.1282 - val_accuracy: 0.6639 - lr: 4.0000e-06\n",
      "Epoch 54/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5420 - accuracy: 0.8331\n",
      "Epoch 54: val_accuracy did not improve from 0.66392\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5420 - accuracy: 0.8331 - val_loss: 1.1295 - val_accuracy: 0.6613 - lr: 4.0000e-06\n",
      "Epoch 55/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5433 - accuracy: 0.8322\n",
      "Epoch 55: val_accuracy did not improve from 0.66392\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5433 - accuracy: 0.8322 - val_loss: 1.1314 - val_accuracy: 0.6617 - lr: 4.0000e-06\n",
      "Epoch 56/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5374 - accuracy: 0.8357\n",
      "Epoch 56: val_accuracy did not improve from 0.66392\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5374 - accuracy: 0.8357 - val_loss: 1.1366 - val_accuracy: 0.6604 - lr: 4.0000e-06\n",
      "Epoch 57/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5311 - accuracy: 0.8371\n",
      "Epoch 57: val_accuracy did not improve from 0.66392\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5311 - accuracy: 0.8371 - val_loss: 1.1409 - val_accuracy: 0.6609 - lr: 4.0000e-06\n",
      "Epoch 58/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5286 - accuracy: 0.8384\n",
      "Epoch 58: val_accuracy did not improve from 0.66392\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5286 - accuracy: 0.8384 - val_loss: 1.1364 - val_accuracy: 0.6631 - lr: 4.0000e-06\n",
      "Epoch 59/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5333 - accuracy: 0.8360\n",
      "Epoch 59: val_accuracy did not improve from 0.66392\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5333 - accuracy: 0.8360 - val_loss: 1.1366 - val_accuracy: 0.6611 - lr: 4.0000e-06\n",
      "Epoch 60/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.8333\n",
      "Epoch 60: val_accuracy did not improve from 0.66392\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5331 - accuracy: 0.8333 - val_loss: 1.1382 - val_accuracy: 0.6622 - lr: 8.0000e-07\n",
      "Epoch 61/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5181 - accuracy: 0.8430\n",
      "Epoch 61: val_accuracy did not improve from 0.66392\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5181 - accuracy: 0.8430 - val_loss: 1.1384 - val_accuracy: 0.6624 - lr: 8.0000e-07\n",
      "Epoch 62/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5301 - accuracy: 0.8377\n",
      "Epoch 62: val_accuracy did not improve from 0.66392\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5301 - accuracy: 0.8377 - val_loss: 1.1362 - val_accuracy: 0.6625 - lr: 8.0000e-07\n",
      "Epoch 63/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.8381\n",
      "Epoch 63: val_accuracy did not improve from 0.66392\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5272 - accuracy: 0.8381 - val_loss: 1.1371 - val_accuracy: 0.6639 - lr: 8.0000e-07\n",
      "Epoch 64/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5307 - accuracy: 0.8355\n",
      "Epoch 64: val_accuracy improved from 0.66392 to 0.66476, saving model to model.h5\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5307 - accuracy: 0.8355 - val_loss: 1.1366 - val_accuracy: 0.6648 - lr: 8.0000e-07\n",
      "Epoch 65/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5248 - accuracy: 0.8377\n",
      "Epoch 65: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 0.5248 - accuracy: 0.8377 - val_loss: 1.1375 - val_accuracy: 0.6643 - lr: 8.0000e-07\n",
      "Epoch 66/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5282 - accuracy: 0.8383\n",
      "Epoch 66: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 67ms/step - loss: 0.5282 - accuracy: 0.8383 - val_loss: 1.1380 - val_accuracy: 0.6634 - lr: 8.0000e-07\n",
      "Epoch 67/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.8379\n",
      "Epoch 67: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5253 - accuracy: 0.8379 - val_loss: 1.1382 - val_accuracy: 0.6639 - lr: 8.0000e-07\n",
      "Epoch 68/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5284 - accuracy: 0.8396\n",
      "Epoch 68: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5284 - accuracy: 0.8396 - val_loss: 1.1368 - val_accuracy: 0.6636 - lr: 8.0000e-07\n",
      "Epoch 69/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5197 - accuracy: 0.8408\n",
      "Epoch 69: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5197 - accuracy: 0.8408 - val_loss: 1.1399 - val_accuracy: 0.6629 - lr: 8.0000e-07\n",
      "Epoch 70/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5274 - accuracy: 0.8388\n",
      "Epoch 70: val_accuracy did not improve from 0.66476\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5274 - accuracy: 0.8388 - val_loss: 1.1389 - val_accuracy: 0.6618 - lr: 8.0000e-07\n",
      "Epoch 71/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5261 - accuracy: 0.8384\n",
      "Epoch 71: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5261 - accuracy: 0.8384 - val_loss: 1.1390 - val_accuracy: 0.6627 - lr: 1.6000e-07\n",
      "Epoch 72/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5216 - accuracy: 0.8411\n",
      "Epoch 72: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5216 - accuracy: 0.8411 - val_loss: 1.1399 - val_accuracy: 0.6628 - lr: 1.6000e-07\n",
      "Epoch 73/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.8409\n",
      "Epoch 73: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5196 - accuracy: 0.8409 - val_loss: 1.1399 - val_accuracy: 0.6622 - lr: 1.6000e-07\n",
      "Epoch 74/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5285 - accuracy: 0.8364\n",
      "Epoch 74: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5285 - accuracy: 0.8364 - val_loss: 1.1386 - val_accuracy: 0.6625 - lr: 1.6000e-07\n",
      "Epoch 75/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5214 - accuracy: 0.8399\n",
      "Epoch 75: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5214 - accuracy: 0.8399 - val_loss: 1.1397 - val_accuracy: 0.6620 - lr: 1.6000e-07\n",
      "Epoch 76/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.8405\n",
      "Epoch 76: val_accuracy did not improve from 0.66476\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5241 - accuracy: 0.8405 - val_loss: 1.1390 - val_accuracy: 0.6625 - lr: 1.6000e-07\n",
      "Epoch 77/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5263 - accuracy: 0.8375\n",
      "Epoch 77: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5263 - accuracy: 0.8375 - val_loss: 1.1391 - val_accuracy: 0.6629 - lr: 3.2000e-08\n",
      "Epoch 78/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5204 - accuracy: 0.8378\n",
      "Epoch 78: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5204 - accuracy: 0.8378 - val_loss: 1.1392 - val_accuracy: 0.6627 - lr: 3.2000e-08\n",
      "Epoch 79/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5246 - accuracy: 0.8377\n",
      "Epoch 79: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5246 - accuracy: 0.8377 - val_loss: 1.1392 - val_accuracy: 0.6625 - lr: 3.2000e-08\n",
      "Epoch 80/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5289 - accuracy: 0.8370\n",
      "Epoch 80: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5289 - accuracy: 0.8370 - val_loss: 1.1401 - val_accuracy: 0.6628 - lr: 3.2000e-08\n",
      "Epoch 81/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5265 - accuracy: 0.8397\n",
      "Epoch 81: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5265 - accuracy: 0.8397 - val_loss: 1.1395 - val_accuracy: 0.6627 - lr: 3.2000e-08\n",
      "Epoch 82/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.8407\n",
      "Epoch 82: val_accuracy did not improve from 0.66476\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5249 - accuracy: 0.8407 - val_loss: 1.1379 - val_accuracy: 0.6629 - lr: 3.2000e-08\n",
      "Epoch 83/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5227 - accuracy: 0.8397\n",
      "Epoch 83: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5227 - accuracy: 0.8397 - val_loss: 1.1383 - val_accuracy: 0.6627 - lr: 6.4000e-09\n",
      "Epoch 84/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5213 - accuracy: 0.8423\n",
      "Epoch 84: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5213 - accuracy: 0.8423 - val_loss: 1.1392 - val_accuracy: 0.6616 - lr: 6.4000e-09\n",
      "Epoch 85/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5295 - accuracy: 0.8363\n",
      "Epoch 85: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5295 - accuracy: 0.8363 - val_loss: 1.1393 - val_accuracy: 0.6621 - lr: 6.4000e-09\n",
      "Epoch 86/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.8402\n",
      "Epoch 86: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5232 - accuracy: 0.8402 - val_loss: 1.1388 - val_accuracy: 0.6624 - lr: 6.4000e-09\n",
      "Epoch 87/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5264 - accuracy: 0.8394\n",
      "Epoch 87: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5264 - accuracy: 0.8394 - val_loss: 1.1386 - val_accuracy: 0.6627 - lr: 6.4000e-09\n",
      "Epoch 88/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.8417\n",
      "Epoch 88: val_accuracy did not improve from 0.66476\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 1.279999928271991e-09.\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5188 - accuracy: 0.8417 - val_loss: 1.1390 - val_accuracy: 0.6624 - lr: 6.4000e-09\n",
      "Epoch 89/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5248 - accuracy: 0.8388\n",
      "Epoch 89: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5248 - accuracy: 0.8388 - val_loss: 1.1384 - val_accuracy: 0.6625 - lr: 1.2800e-09\n",
      "Epoch 90/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5283 - accuracy: 0.8375\n",
      "Epoch 90: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5283 - accuracy: 0.8375 - val_loss: 1.1387 - val_accuracy: 0.6622 - lr: 1.2800e-09\n",
      "Epoch 91/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5255 - accuracy: 0.8382\n",
      "Epoch 91: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5255 - accuracy: 0.8382 - val_loss: 1.1364 - val_accuracy: 0.6631 - lr: 1.2800e-09\n",
      "Epoch 92/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5245 - accuracy: 0.8391\n",
      "Epoch 92: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5245 - accuracy: 0.8391 - val_loss: 1.1393 - val_accuracy: 0.6627 - lr: 1.2800e-09\n",
      "Epoch 93/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5173 - accuracy: 0.8424\n",
      "Epoch 93: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5173 - accuracy: 0.8424 - val_loss: 1.1381 - val_accuracy: 0.6624 - lr: 1.2800e-09\n",
      "Epoch 94/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5208 - accuracy: 0.8389\n",
      "Epoch 94: val_accuracy did not improve from 0.66476\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 2.55999976772614e-10.\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5208 - accuracy: 0.8389 - val_loss: 1.1394 - val_accuracy: 0.6628 - lr: 1.2800e-09\n",
      "Epoch 95/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.8374\n",
      "Epoch 95: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5272 - accuracy: 0.8374 - val_loss: 1.1404 - val_accuracy: 0.6622 - lr: 2.5600e-10\n",
      "Epoch 96/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5260 - accuracy: 0.8403\n",
      "Epoch 96: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5260 - accuracy: 0.8403 - val_loss: 1.1366 - val_accuracy: 0.6622 - lr: 2.5600e-10\n",
      "Epoch 97/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5278 - accuracy: 0.8388\n",
      "Epoch 97: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5278 - accuracy: 0.8388 - val_loss: 1.1397 - val_accuracy: 0.6625 - lr: 2.5600e-10\n",
      "Epoch 98/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5290 - accuracy: 0.8360\n",
      "Epoch 98: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5290 - accuracy: 0.8360 - val_loss: 1.1376 - val_accuracy: 0.6627 - lr: 2.5600e-10\n",
      "Epoch 99/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.8375\n",
      "Epoch 99: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5253 - accuracy: 0.8375 - val_loss: 1.1378 - val_accuracy: 0.6622 - lr: 2.5600e-10\n",
      "Epoch 100/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5264 - accuracy: 0.8383\n",
      "Epoch 100: val_accuracy did not improve from 0.66476\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 5.119999424429978e-11.\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5264 - accuracy: 0.8383 - val_loss: 1.1378 - val_accuracy: 0.6628 - lr: 2.5600e-10\n",
      "Epoch 101/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5238 - accuracy: 0.8405\n",
      "Epoch 101: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5238 - accuracy: 0.8405 - val_loss: 1.1389 - val_accuracy: 0.6621 - lr: 5.1200e-11\n",
      "Epoch 102/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5248 - accuracy: 0.8379\n",
      "Epoch 102: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5248 - accuracy: 0.8379 - val_loss: 1.1386 - val_accuracy: 0.6628 - lr: 5.1200e-11\n",
      "Epoch 103/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.8372\n",
      "Epoch 103: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5269 - accuracy: 0.8372 - val_loss: 1.1371 - val_accuracy: 0.6627 - lr: 5.1200e-11\n",
      "Epoch 104/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.8405\n",
      "Epoch 104: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5241 - accuracy: 0.8405 - val_loss: 1.1382 - val_accuracy: 0.6625 - lr: 5.1200e-11\n",
      "Epoch 105/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5258 - accuracy: 0.8382\n",
      "Epoch 105: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5258 - accuracy: 0.8382 - val_loss: 1.1396 - val_accuracy: 0.6624 - lr: 5.1200e-11\n",
      "Epoch 106/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5231 - accuracy: 0.8385\n",
      "Epoch 106: val_accuracy did not improve from 0.66476\n",
      "\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 1.0239999126415712e-11.\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5231 - accuracy: 0.8385 - val_loss: 1.1398 - val_accuracy: 0.6625 - lr: 5.1200e-11\n",
      "Epoch 107/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5279 - accuracy: 0.8400\n",
      "Epoch 107: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5279 - accuracy: 0.8400 - val_loss: 1.1388 - val_accuracy: 0.6625 - lr: 1.0240e-11\n",
      "Epoch 108/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5223 - accuracy: 0.8398\n",
      "Epoch 108: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5223 - accuracy: 0.8398 - val_loss: 1.1399 - val_accuracy: 0.6622 - lr: 1.0240e-11\n",
      "Epoch 109/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.8398\n",
      "Epoch 109: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5229 - accuracy: 0.8398 - val_loss: 1.1389 - val_accuracy: 0.6625 - lr: 1.0240e-11\n",
      "Epoch 110/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5303 - accuracy: 0.8372\n",
      "Epoch 110: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5303 - accuracy: 0.8372 - val_loss: 1.1391 - val_accuracy: 0.6629 - lr: 1.0240e-11\n",
      "Epoch 111/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.8400\n",
      "Epoch 111: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5256 - accuracy: 0.8400 - val_loss: 1.1392 - val_accuracy: 0.6627 - lr: 1.0240e-11\n",
      "Epoch 112/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5248 - accuracy: 0.8368\n",
      "Epoch 112: val_accuracy did not improve from 0.66476\n",
      "\n",
      "Epoch 112: ReduceLROnPlateau reducing learning rate to 2.0479997905886727e-12.\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5248 - accuracy: 0.8368 - val_loss: 1.1401 - val_accuracy: 0.6616 - lr: 1.0240e-11\n",
      "Epoch 113/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.8348\n",
      "Epoch 113: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5272 - accuracy: 0.8348 - val_loss: 1.1375 - val_accuracy: 0.6631 - lr: 2.0480e-12\n",
      "Epoch 114/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5206 - accuracy: 0.8419\n",
      "Epoch 114: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5206 - accuracy: 0.8419 - val_loss: 1.1393 - val_accuracy: 0.6624 - lr: 2.0480e-12\n",
      "Epoch 115/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5116 - accuracy: 0.8425\n",
      "Epoch 115: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5116 - accuracy: 0.8425 - val_loss: 1.1387 - val_accuracy: 0.6627 - lr: 2.0480e-12\n",
      "Epoch 116/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.8379\n",
      "Epoch 116: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5257 - accuracy: 0.8379 - val_loss: 1.1360 - val_accuracy: 0.6638 - lr: 2.0480e-12\n",
      "Epoch 117/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5214 - accuracy: 0.8404\n",
      "Epoch 117: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5214 - accuracy: 0.8404 - val_loss: 1.1394 - val_accuracy: 0.6625 - lr: 2.0480e-12\n",
      "Epoch 118/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5246 - accuracy: 0.8399\n",
      "Epoch 118: val_accuracy did not improve from 0.66476\n",
      "\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 4.0959995811773456e-13.\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5246 - accuracy: 0.8399 - val_loss: 1.1390 - val_accuracy: 0.6627 - lr: 2.0480e-12\n",
      "Epoch 119/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.8358\n",
      "Epoch 119: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5262 - accuracy: 0.8358 - val_loss: 1.1401 - val_accuracy: 0.6618 - lr: 4.0960e-13\n",
      "Epoch 120/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5237 - accuracy: 0.8373\n",
      "Epoch 120: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5237 - accuracy: 0.8373 - val_loss: 1.1390 - val_accuracy: 0.6627 - lr: 4.0960e-13\n",
      "Epoch 121/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5242 - accuracy: 0.8378\n",
      "Epoch 121: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5242 - accuracy: 0.8378 - val_loss: 1.1388 - val_accuracy: 0.6627 - lr: 4.0960e-13\n",
      "Epoch 122/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5284 - accuracy: 0.8395\n",
      "Epoch 122: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5284 - accuracy: 0.8395 - val_loss: 1.1381 - val_accuracy: 0.6628 - lr: 4.0960e-13\n",
      "Epoch 123/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5278 - accuracy: 0.8395\n",
      "Epoch 123: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5278 - accuracy: 0.8395 - val_loss: 1.1391 - val_accuracy: 0.6622 - lr: 4.0960e-13\n",
      "Epoch 124/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.8396\n",
      "Epoch 124: val_accuracy did not improve from 0.66476\n",
      "\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 8.191999053934474e-14.\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5236 - accuracy: 0.8396 - val_loss: 1.1402 - val_accuracy: 0.6628 - lr: 4.0960e-13\n",
      "Epoch 125/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5205 - accuracy: 0.8405\n",
      "Epoch 125: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5205 - accuracy: 0.8405 - val_loss: 1.1396 - val_accuracy: 0.6625 - lr: 8.1920e-14\n",
      "Epoch 126/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.8381\n",
      "Epoch 126: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5256 - accuracy: 0.8381 - val_loss: 1.1390 - val_accuracy: 0.6629 - lr: 8.1920e-14\n",
      "Epoch 127/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5194 - accuracy: 0.8405\n",
      "Epoch 127: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5194 - accuracy: 0.8405 - val_loss: 1.1381 - val_accuracy: 0.6627 - lr: 8.1920e-14\n",
      "Epoch 128/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5304 - accuracy: 0.8368\n",
      "Epoch 128: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5304 - accuracy: 0.8368 - val_loss: 1.1375 - val_accuracy: 0.6625 - lr: 8.1920e-14\n",
      "Epoch 129/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5285 - accuracy: 0.8344\n",
      "Epoch 129: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5285 - accuracy: 0.8344 - val_loss: 1.1378 - val_accuracy: 0.6629 - lr: 8.1920e-14\n",
      "Epoch 130/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5203 - accuracy: 0.8402\n",
      "Epoch 130: val_accuracy did not improve from 0.66476\n",
      "\n",
      "Epoch 130: ReduceLROnPlateau reducing learning rate to 1.638399837891949e-14.\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5203 - accuracy: 0.8402 - val_loss: 1.1381 - val_accuracy: 0.6622 - lr: 8.1920e-14\n",
      "Epoch 131/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5237 - accuracy: 0.8402\n",
      "Epoch 131: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5237 - accuracy: 0.8402 - val_loss: 1.1390 - val_accuracy: 0.6624 - lr: 1.6384e-14\n",
      "Epoch 132/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5213 - accuracy: 0.8409\n",
      "Epoch 132: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5213 - accuracy: 0.8409 - val_loss: 1.1387 - val_accuracy: 0.6631 - lr: 1.6384e-14\n",
      "Epoch 133/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5222 - accuracy: 0.8379\n",
      "Epoch 133: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5222 - accuracy: 0.8379 - val_loss: 1.1382 - val_accuracy: 0.6627 - lr: 1.6384e-14\n",
      "Epoch 134/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.8397\n",
      "Epoch 134: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5269 - accuracy: 0.8397 - val_loss: 1.1385 - val_accuracy: 0.6629 - lr: 1.6384e-14\n",
      "Epoch 135/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5218 - accuracy: 0.8381\n",
      "Epoch 135: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5218 - accuracy: 0.8381 - val_loss: 1.1377 - val_accuracy: 0.6629 - lr: 1.6384e-14\n",
      "Epoch 136/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5295 - accuracy: 0.8389\n",
      "Epoch 136: val_accuracy did not improve from 0.66476\n",
      "\n",
      "Epoch 136: ReduceLROnPlateau reducing learning rate to 3.27679981130917e-15.\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5295 - accuracy: 0.8389 - val_loss: 1.1399 - val_accuracy: 0.6620 - lr: 1.6384e-14\n",
      "Epoch 137/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5261 - accuracy: 0.8388\n",
      "Epoch 137: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5261 - accuracy: 0.8388 - val_loss: 1.1394 - val_accuracy: 0.6624 - lr: 3.2768e-15\n",
      "Epoch 138/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5230 - accuracy: 0.8406\n",
      "Epoch 138: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5230 - accuracy: 0.8406 - val_loss: 1.1401 - val_accuracy: 0.6625 - lr: 3.2768e-15\n",
      "Epoch 139/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5212 - accuracy: 0.8396\n",
      "Epoch 139: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5212 - accuracy: 0.8396 - val_loss: 1.1382 - val_accuracy: 0.6628 - lr: 3.2768e-15\n",
      "Epoch 140/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5281 - accuracy: 0.8364\n",
      "Epoch 140: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5281 - accuracy: 0.8364 - val_loss: 1.1392 - val_accuracy: 0.6621 - lr: 3.2768e-15\n",
      "Epoch 141/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5281 - accuracy: 0.8370\n",
      "Epoch 141: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5281 - accuracy: 0.8370 - val_loss: 1.1395 - val_accuracy: 0.6631 - lr: 3.2768e-15\n",
      "Epoch 142/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.8385\n",
      "Epoch 142: val_accuracy did not improve from 0.66476\n",
      "\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 6.553599792024929e-16.\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5236 - accuracy: 0.8385 - val_loss: 1.1389 - val_accuracy: 0.6628 - lr: 3.2768e-15\n",
      "Epoch 143/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5255 - accuracy: 0.8387\n",
      "Epoch 143: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 29s 66ms/step - loss: 0.5255 - accuracy: 0.8387 - val_loss: 1.1380 - val_accuracy: 0.6627 - lr: 6.5536e-16\n",
      "Epoch 144/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5204 - accuracy: 0.8412\n",
      "Epoch 144: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5204 - accuracy: 0.8412 - val_loss: 1.1373 - val_accuracy: 0.6631 - lr: 6.5536e-16\n",
      "Epoch 145/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5240 - accuracy: 0.8386\n",
      "Epoch 145: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5240 - accuracy: 0.8386 - val_loss: 1.1365 - val_accuracy: 0.6635 - lr: 6.5536e-16\n",
      "Epoch 146/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5245 - accuracy: 0.8405\n",
      "Epoch 146: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5245 - accuracy: 0.8405 - val_loss: 1.1393 - val_accuracy: 0.6625 - lr: 6.5536e-16\n",
      "Epoch 147/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5221 - accuracy: 0.8420\n",
      "Epoch 147: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5221 - accuracy: 0.8420 - val_loss: 1.1396 - val_accuracy: 0.6622 - lr: 6.5536e-16\n",
      "Epoch 148/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5190 - accuracy: 0.8400\n",
      "Epoch 148: val_accuracy did not improve from 0.66476\n",
      "\n",
      "Epoch 148: ReduceLROnPlateau reducing learning rate to 1.3107199584049857e-16.\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5190 - accuracy: 0.8400 - val_loss: 1.1394 - val_accuracy: 0.6622 - lr: 6.5536e-16\n",
      "Epoch 149/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5209 - accuracy: 0.8390\n",
      "Epoch 149: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 30s 66ms/step - loss: 0.5209 - accuracy: 0.8390 - val_loss: 1.1366 - val_accuracy: 0.6634 - lr: 1.3107e-16\n",
      "Epoch 150/150\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5216 - accuracy: 0.8402\n",
      "Epoch 150: val_accuracy did not improve from 0.66476\n",
      "448/448 [==============================] - 35s 77ms/step - loss: 0.5216 - accuracy: 0.8402 - val_loss: 1.1372 - val_accuracy: 0.6632 - lr: 1.3107e-16\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n//training_set.batch_size\n",
    "validation_steps = test_set.n//test_set.batch_size\n",
    "\n",
    "hist = fernet.fit(training_set,\n",
    "                  validation_data = test_set,\n",
    "                  epochs = 150,\n",
    "                  callbacks = callbacks,\n",
    "                  steps_per_epoch = steps_per_epoch,\n",
    "                  validation_steps = validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x175bcb4c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28b2c8700>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 18:28:32.391223: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 12s 26ms/step - loss: 0.3722 - accuracy: 0.9067\n",
      "113/113 [==============================] - 3s 26ms/step - loss: 1.1830 - accuracy: 0.6726\n",
      "final train accuracy = 90.67 , validation accuracy = 67.26\n"
     ]
    }
   ],
   "source": [
    "fernet = load_model('../Emotion-Detection/model/fernet.h5')\n",
    "train_loss, train_accu = fernet.evaluate(training_set)\n",
    "test_loss, test_accu = fernet.evaluate(test_set)\n",
    "print(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_accu*100, test_accu*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 18:29:08.240692: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../Emotion-Detection/model/model.h5')\n",
    "\n",
    "face_clsfr=cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "labels_dict={0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Neutral',5:'Sad',6:'Surprise'}\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret,img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_clsfr.detectMultiScale(gray,1.3,3) \n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "    \n",
    "        face_img = gray[y:y+w,x:x+w]\n",
    "        resized = cv2.resize(face_img,(48,48))\n",
    "        normalized = resized/255.0\n",
    "        reshaped = np.reshape(normalized,(1,48,48,1))\n",
    "        result = model.predict(reshaped)\n",
    "\n",
    "        label = np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        cv2.rectangle(img,(x,y-40),(x+w,y),(0,0,0),-1)\n",
    "        cv2.putText(img, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)    \n",
    "\n",
    "        \n",
    "    cv2.imshow('Emotion Recognition',img)\n",
    "#     out.write(img)\n",
    "    key=cv2.waitKey(1)\n",
    "    \n",
    "    if(key==27):\n",
    "        break\n",
    "    if ret==False:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fdca9c13b9247844f509ae058765d7e690bb5d41d0c33f4bc61aac5df284431"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
